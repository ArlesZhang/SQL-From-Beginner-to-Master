# 今日学习总结：Hive SQL 复杂查询执行与分批执行策略

## 1️⃣ 分批执行 vs 一次性执行

### **核心判断逻辑**
> **判断能否一次执行**，先看它是不是“一条完整的 SQL 语句”，再看后面的语句是否依赖前面的结果。  
> - **有依赖** → 建议分批执行（同一会话内），保证依赖成立，方便调试  
> - **无依赖** → 一次性或分批都行，互不影响

### **依赖的本质**
- 分批执行 ≠ 独立执行  
- 在**同一个会话**中，前面执行的结果（表、函数、变量）会保留，后续 SQL 可以直接使用  
- 如果换会话，临时对象会丢失，依赖断开

---

## 2️⃣ 商业化场景下的执行策略

### **为什么不能总是手动分批**
- 人工分批效率低、容易出错
- 生产环境需要自动化调度（Airflow / Azkaban / DolphinScheduler）
- 复杂 SQL 可能有几十上百行，手动拆分不现实

### **最佳实践**
| 场景 | 推荐方式 | 是否一次性执行 |
|------|----------|----------------|
| 开发调试 | 分批执行（方便看中间结果） | 否 |
| 生产定时任务 | 脚本 + 调度系统 | 是 |
| 一次性分析 | CTE（WITH 子句） | 是 |
| 多次复用 | 持久化中间表（CREATE TABLE AS SELECT） | 是 |

**一句话记忆**：
> 开发调试分批跑，生产调度一次跑；一次分析用 CTE，多次复用落地表。

---

## 3️⃣ Hive 中的 `dt` 条件

### **`dt` 的含义**
- 在 Hive 中，`dt` 通常是**分区字段**（partition column），代表数据的日期分区
- `dt='2025-05-28'` 的作用是**分区裁剪**（Partition Pruning），只扫描对应分区的数据

### **是否可以去掉**
- **可以去掉**：想分析所有日期数据，且不在乎性能
- **不建议去掉**：表是分区表且数据量大，需要性能优化
- 如果 `dt` 和 `dialog_start_time` 表示同一日期，建议只保留 `dt` 条件

---

## 4️⃣ 复杂 SQL 的封装与复用

### **常见封装方式**
1. **子查询 / CTE**：适合一次性分析
2. **临时表（TEMPORARY TABLE）**：适合开发调试、会话内多次复用
3. **永久表（CREATE TABLE AS SELECT）**：适合生产中间层
4. **视图（VIEW）**：逻辑封装，不占存储，但每次执行会重新计算
5. **物化视图（Materialized View）**：存储结果，性能好，可自动刷新

### **建议**
- 开发调试 → 临时表
- 生产复用 → 永久表 / 物化视图
- 一次性分析 → CTE
- 逻辑封装 → 视图

### 黄金实践指南（总结）
为了写出最通用、最不容易出错的SQL脚本，请遵循以下法则：

1.  **默认假设环境是“严格的”**：总是假设你的脚本会在Hive CLI这种需要显式分隔的环境中运行。
2.  **显式使用分号`;`**：在每个独立的语句（尤其是DDL）后面都加上分号。
3.  **了解你的工具**：弄清楚你用的IDE（DBeaver、DataGrip等）的 **“执行脚本”** 和 **“执行语句”** 快捷键分别是哪个。
4. SQL 脚本的编译 & 执行逻辑，和 **C语言头文件/函数声明** 很像：
	- **DDL（定义语句，CREATE / ALTER / DROP …）** 会改变数据库的“元信息”（元数据库里表/视图/索引的定义）。
	- **DML（操作语句，SELECT / INSERT / UPDATE …）** 在编译时必须能查到对应对象的定义。
	所以：  
	如果你把 **所有 DDL 写在脚本的最前面**，就相当于在编译阶段，数据库已经知道有哪些表存在（哪怕表是空的），那么后面所有的 DML 在编译时就不会再报“表不存在”的错了。

**你的脚本应该永远这样写：**
```sql
-- ################# Batch 1: Register UDF #################
CREATE TEMPORARY FUNCTION UDFJsonAsArray AS 'cn.xxx.UDFJsonAsArray'
USING JAR 'hdfs://path/to.jar';

-- ################# Batch 2: Create Temp Table #################
CREATE TEMPORARY TABLE IF NOT EXISTS record_check_tmp1 AS 
SELECT ... 
LATERAL VIEW EXPLODE(...) ...;

-- ################# Batch 3: Main Query #################
SELECT 
    ...
FROM ...
LEFT JOIN ...;

-- ✅ 推荐写法：DDL 在前                                      
CREATE TEMPORARY TABLE my_temp_table AS 
SELECT ...;

-- 之后的 DML 就可以直接用了                                            
SELECT * FROM my_temp_table;
INSERT INTO my_temp_table VALUES (...);
```

按照这个规则，你的脚本在任何工具和环境中都能稳定运行。

---

## 5️⃣ 今日关键收获
- **分批执行的本质**：是为了按顺序满足依赖，不是让语句互相独立
- **一次性执行的前提**：语句完整且无依赖，或依赖已在同一会话中提前满足
- **商业化落地**：用脚本化、调度化、封装化替代人工分批
- **Hive 性能优化**：分区字段（如 `dt`）过滤是关键，能极大减少扫描数据量

---

## 💡 思考
1. 在你的工作中，是否遇到过因为**没有分区裁剪**导致 Hive 查询特别慢的情况？你是怎么优化的？
2. 如果一个复杂 SQL 有 5 个依赖步骤，你会选择**CTE 一次性执行**还是**中间表分步执行**？为什么？
3. 你觉得在生产环境中，**物化视图**相比**永久中间表**的优势和劣势分别是什么？

